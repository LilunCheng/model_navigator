{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to using Model Navigator functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "- Docker\n",
    "\n",
    "#### Starting JupyterLab notebook\n",
    "Use `start_notebook.sh` script located in the same directory as notebook `export_demo.ipynb` to start JupyterLab. It will pull Docker image and start container with notebook within. Then use URL printed in console to access notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Navigator Export from src consists of 3 parts:\n",
    "1. Export\n",
    "  1. Tests all export / conversion / runtime paths\n",
    "  2. Not everything must pass\n",
    "    1. (e.g. if ONNX-TRT is not supported, you can open a bug on Microsoft ONNX, but there is no guarantee they will support it any time soon)\n",
    "  3. Minimal deployment paths\n",
    "    1. [Navigator action] Export TorchScript (trace, script) or ONNX (trace)\n",
    "        1. [User action] At least one path must be ensured by user, adjust / refactor your model to support export to TorchScript or ONNX\n",
    "    2. [Navigator action] Correctness\n",
    "    3. [Navigator action] Conversion\n",
    "    4. [Navigator action] Performance\n",
    "2. [non blocking User action] Model verification (MN is unable to automatically verify accuracy, we need user input to do that, by verifying exported / converted models on their metric function and setting the flag. Action is described as non-blocking because we can work without it just cannot verify model automatically)\n",
    "  1. For desired deployment paths, user is responsible for model accuracy verification and set verified flag True\n",
    "    1. TorchScript or ONNX\n",
    "    2. [optional] Torch-TRT or TRT if available\n",
    "3. Model save for distribution\n",
    "  1. Save model in base format for distribution with information about successful conversions and verified models\n",
    "\n",
    "[Documentation](https://github.com/triton-inference-server/model_navigator/blob/main/README.md) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install Model Navigator Export API for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "!cd /model_navigator && pip install --extra-index-url https://pypi.ngc.nvidia.com .[pyt,huggingface]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Examples, PyTorch, ResNet50 example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone Deep Learning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/DeepLearningExamples DeepLearningExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DeepLearningExamples directory to path and then import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./DeepLearningExamples/PyTorch/Classification/ConvNets/\")\n",
    "from image_classification import models as convnet_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dataloader\n",
    "dataloader is iterable that contains tensors. In this example it is random torch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dataloader = [torch.randn(1, 3, 224, 224, device=\"cuda\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model_navigator and use export function to export all possible formats for ResNet50 PyTorch\n",
    "\n",
    "Model Navigator export API will automatically perform following actions:\n",
    "1. export model from source code\n",
    "2. convert model\n",
    "3. correctness test on source and converted model outputs\n",
    "4. performance evaluation\n",
    "\n",
    "All artifacts will be stored inside `navigator_workdir/resnet50_pyt.nav.workspace` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_navigator as nav\n",
    "\n",
    "source_model = convnet_models.resnet50(pretrained=True).eval()\n",
    "\n",
    "pkg_desc = nav.torch.export(\n",
    "   model=source_model,\n",
    "   model_name=\"resnet50_pyt\",\n",
    "   dataloader=dataloader,\n",
    "   target_device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ONNX Polygraphy runner for exported ONNX model and verify outputs\n",
    "\n",
    "After exporting models, user have to manually verify them. It can be done by accessing model with `PackageDescriptor` and `get_model` function.\n",
    "\n",
    "Loaded model can be used for inference, then outputs can be used for calculating custom metrics.\n",
    "\n",
    "If model accuracy is valid then selected format can be set as verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "feed_dict = {\"input__0\": dataloader[0].detach().cpu().numpy()}\n",
    "\n",
    "# Compare in framework model and exported model outputs\n",
    "output_a = [source_model(dataloader[0]).detach().cpu().numpy()]\n",
    "\n",
    "onnx_runner = pkg_desc.get_runner(format=nav.Format.ONNX, runtime=nav.RuntimeProvider.CUDA)\n",
    "with onnx_runner:\n",
    "    output_b = onnx_runner.infer(feed_dict)\n",
    "    \n",
    "for a, b in zip(output_a, output_b.values()):\n",
    "     assert numpy.allclose(a, b, atol=0.01, rtol=0.01)\n",
    "    \n",
    "pkg_desc.set_verified(format=nav.Format.ONNX, runtime=nav.RuntimeProvider.CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get TorchScript model and verify outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\"input__0\": dataloader[0].detach().cpu().numpy()}\n",
    "    \n",
    "# Compare in framework model and exported model outputs\n",
    "output_a = source_model(dataloader[0]).detach().cpu().numpy()\n",
    "\n",
    "ts_runner = pkg_desc.get_runner(format=nav.Format.TORCHSCRIPT, jit_type=nav.JitType.SCRIPT)\n",
    "with ts_runner:\n",
    "    output_b = ts_runner.infer(feed_dict)\n",
    "\n",
    "for a, b in zip(output_a, output_b.values()):\n",
    "     assert numpy.allclose(a, b, atol=0, rtol=0)\n",
    "            \n",
    "pkg_desc.set_verified(format=nav.Format.TORCHSCRIPT, jit_type=nav.JitType.SCRIPT, runtime=nav.RuntimeProvider.PYT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save navigator package\n",
    "After verification of selected formats user have to save navigator package. It will contain base formats (`TorchScript, ONNX`) and all information and statuses obtained during execution. Navigator package can be used latter to create all other formats (`Torch-TRT, TRT`) and rerurn tests.\n",
    "\n",
    "This process will log warnings only for formats and runtimes that were not verified in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nav.save(pkg_desc, \"resnet50_pyt.nav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace, PyTorch, distilbert-base-uncased example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_navigator as nav\n",
    "\n",
    "export_config = {\n",
    "    \"model_name\": \"distilbert-base-uncased\",\n",
    "    \"dataset_name\": \"imdb\",\n",
    "    \"padding\": \"max_length\",\n",
    "    \"max_sequence_len\": 384,\n",
    "    \"max_bs\": 2,\n",
    "    \"sample_count\": 10,\n",
    "}\n",
    "\n",
    "pkg_desc = nav.contrib.huggingface.torch.export(**export_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save distilbert without verification\n",
    "Even if you do not have access to dataset or source model, you still can save Navigator package. This process will log warnings for all formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav.save(pkg_desc, \"distilbert_base_uncased.nav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "Copyright (c) 2021-2022, NVIDIA CORPORATION. All rights reserved.\n",
     "\n",
     "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
     "you may not use this file except in compliance with the License.\n",
     "You may obtain a copy of the License at\n",
     "\n",
     "     http://www.apache.org/licenses/LICENSE-2.0\n",
     "\n",
     "Unless required by applicable law or agreed to in writing, software\n",
     "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
     "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
     "See the License for the specific language governing permissions and\n",
     "limitations under the License.\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
