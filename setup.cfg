# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
[bumpversion]
current_version = 0.2.0
commit = True
tag = True

[metadata]
name = model_navigator
version = attr: model_navigator.__init__.__version__
description = model_navigator provides tools supporting to create Deep Learning production ready inference services
long_description = file: README.md, CHANGELOG.md, LICENSE
long_description_content_type = text/markdown
url = https://github.com/triton-inference-server/model_navigator
keywords = triton, tensorrt, inference, server, service, nvidia, onnx, tensorflow pytorch
license = Apache Software License 2.0
classifiers =
	"Development Status :: 2 - Pre-Alpha",
	"Intended Audience :: Developers",
	"License :: OSI Approved :: Apache Software License",
	"Natural Language :: English",
	"Programming Language :: Python :: 3.6",
	"Programming Language :: Python :: 3.7",
	"Programming Language :: Python :: 3.8",
	"Programming Language :: Python :: 3.9",

[options]
zip_safe = False
include_package_data = True
packages = find:
python_requires > = 3.6
install_requires =
	numpy>=1.19.0
	PyYaml>=5.2
	ruamel.yaml>=0.15.0
	protobuf>=3.12.4
	docker>=4.4.1
	dockerpty>=0.4.1
	onnx>=1.8.1
	tabulate>=0.8.7
	sh>=1.14.1
	jinja2>=2.11.3
	tqdm>=4.57.0
	colored>=1.4.2
	coloredlogs>=15.0.0
	click>=8.0.0
	dacite>=1.6.0
	semver>=2.13.0,<3.0.0
	typing_inspect>=0.6.0
	dataclasses>=0.8.0; python_version<'3.7'
	polygraphy @ https://developer.download.nvidia.com/compute/redist/polygraphy/polygraphy-0.31.1-py2.py3-none-any.whl
	tritonclient[all] @ https://developer.download.nvidia.com/compute/redist/tritonclient/tritonclient-2.12.0-py3-none-manylinux1_x86_64.whl
	triton-model-analyzer @ https://developer.download.nvidia.com/compute/redist/triton-model-analyzer/triton_model_analyzer-1.6.0-py3-none-manylinux1_x86_64.whl

[options.package_data]
* = Dockerfile, Dockerfile.*, templates/*.tpl, templates/*.jinja2, examples/quick-start/model.pt, version.yaml

[options.entry_points]
console_scripts =
	model-navigator = model_navigator.cli.main:main

[options.extras_require]
tf =
	onnx_graphsurgeon @ https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.11-py2.py3-none-any.whl
	onnxruntime-gpu>=1.7.1
	tf2onnx @ git+https://github.com/onnx/tensorflow-onnx.git@v1.9.1#egg=tf2onnx-1.9.1
    onnx==1.8.1
pyt =
	onnx_graphsurgeon @ https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.11-py2.py3-none-any.whl
	onnxruntime-gpu>=1.7.1
cloud =
	google-cloud-storage>=1.36.0
	boto3>=1.17.13
	azure-storage-blob>=12.7.0

[bumpversion:file:model_navigator/__init__.py]
search = __version__ = "{current_version}"
replace = __version__ = "{new_version}"

[flake8]
exclude = docs
ignore = E203, E266, E501, W503
max-line-length = 88
max-complexity = 18
select = B,C,E,F,W,T4

[aliases]
test = pytest

[mypy]
python_version = 3.6
platform = linux
show_column_numbers = True
follow_imports = normal
ignore_missing_imports = True
disallow_untyped_calls = True
warn_return_any = True
strict_optional = True
warn_no_return = True
warn_redundant_casts = True
warn_unused_ignores = True
cache_dir = /dev/null

[mypy-_version]
follow_imports = skip
