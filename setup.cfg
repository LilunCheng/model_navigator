[bumpversion]
current_version = 0.1.0
commit = True
tag = True

[metadata]
name = model_navigator
version = attr: model_navigator.__init__.__version__
description = model_navigator provides tools supporting to create Deep Learning production ready inference services
long_description = file: README.md, CHANGELOG.md, LICENSE
long_description_content_type = text/markdown
url = https://github.com/triton-inference-server/model_navigator
keywords = triton, tensorrt, inference, server, service, nvidia, onnx, tensorflow pytorch
license = Apache Software License 2.0
classifiers = 
	"Development Status :: 2 - Pre-Alpha",
	"Intended Audience :: Developers",
	"License :: OSI Approved :: Apache Software License",
	"Natural Language :: English",
	"Programming Language :: Python :: 3.6",
	"Programming Language :: Python :: 3.7",
	"Programming Language :: Python :: 3.8",
	"Programming Language :: Python :: 3.9",

[options]
zip_safe = False
include_package_data = True
packages = find:
python_requires > = 3.6
scripts = 
	model_navigator/cli/config_model_on_triton.py
	model_navigator/cli/convert_model.py
	model_navigator/cli/download_file.py
	model_navigator/cli/run_offline_performance_test_on_triton.py
	model_navigator/cli/run_online_performance_test_on_triton.py
install_requires = 
	numpy>=1.19.0,<1.20
	PyYaml>=5.2
	protobuf>=3.12.4
	docker>=4.4.1
	onnx>=1.8.0
	wrapt>=1.12.1
	tabulate>=0.8.7
	natsort>=7.0.0
	attrs>=20.3.0
	sh>=1.14.1
	pyaml>=20.4.0
	jinja2>=2.11.3
	tqdm>=4.57.0
	google-cloud-storage>=1.36.0
	boto3>=1.17.13
	azure-storage-blob>=12.7.0
	colored>=1.4.2
	importlib_metadata; python_version<'3.8'
	polygraphy @ git+https://github.com/NVIDIA/TensorRT.git@89d796421#egg=polygraphy-0.21.1&subdirectory=tools/Polygraphy
	tritonclient[all] @ https://developer.download.nvidia.com/compute/redist/tritonclient/tritonclient-2.7.0-py3-none-manylinux1_x86_64.whl
	triton-model-analyzer @ git+https://github.com/triton-inference-server/model_analyzer@616e8a30

[options.package_data]
* = Dockerfile, templates/*.tpl, templates/*.jinja2, examples/quick-start/model.pt

[options.entry_points]
console_scripts = 
	model-navigator = model_navigator.entrypoint:main

[options.extras_require]
tf = 
	tf2onnx@git+https://github.com/onnx/tensorflow-onnx.git@v1.8.4#egg=tf2onnx
	onnxruntime>=1.6.0
	onnx_graphsurgeon @ git+https://github.com/NVIDIA/TensorRT.git@89d796421#egg=onnx_graphsurgeon-0.3.3&subdirectory=tools/onnx-graphsurgeon
pyt = 
	onnxruntime>=1.6.0
	onnx_graphsurgeon @ git+https://github.com/NVIDIA/TensorRT.git@89d796421#egg=onnx_graphsurgeon-0.3.3&subdirectory=tools/onnx-graphsurgeon

[bumpversion:file:model_navigator/__init__.py]
search = __version__ = "{current_version}"
replace = __version__ = "{new_version}"

[flake8]
exclude = docs
ignore = E203, E266, E501, W503
max-line-length = 88
max-complexity = 18
select = B,C,E,F,W,T4

[aliases]
test = pytest

[mypy]
python_version = 3.6
platform = linux
show_column_numbers = True
follow_imports = normal
ignore_missing_imports = True
disallow_untyped_calls = True
warn_return_any = True
strict_optional = True
warn_no_return = True
warn_redundant_casts = True
warn_unused_ignores = True
cache_dir = /dev/null

[mypy-_version]
follow_imports = skip
